{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10054e4",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6205ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inputdata import *\n",
    "from all_libraries import*\n",
    "from data_to_ml import *\n",
    "from pdb import set_trace\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.rcParams.update({'font.size': 20})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f50accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_ml():\n",
    "        \"\"\"Calling Object Data Survey\"\"\"\n",
    "        data = EDAworkflow()\n",
    "        # Tipi and das ready for analysis\n",
    "        tipi = data.get_personality(data)\n",
    "        das = data.get_belief_system(data)\n",
    "\n",
    "        # Ifluence scores\n",
    "\n",
    "        techniques = data.get_techniques(data)\n",
    "        demo = data.get_demographics(data)\n",
    "        df = pd.concat([demo,tipi,das,techniques],axis=1).astype(int)\n",
    "\n",
    "        # Selected input features\n",
    "        X = df[['age', 'gender', 'education', 'Extraverted, enthusiastic',\n",
    "               'Critical, quarrelsome', 'Dependable, self-disciplined',\n",
    "               'Anxious, easily upset', 'Open to new experiences', 'Reserved, quiet',\n",
    "               'Sympathetic, warm', 'Disorganized, careless',\n",
    "               'Calm, emotionally stable', 'Conventional, uncreative', 'das1',\n",
    "               'das2', 'das3', 'das4', 'das5', 'das6', 'das7', 'das8', 'das9',\n",
    "               'das10', 'das11', 'das12', 'das13', 'das14', 'das15', 'das16', 'das17',\n",
    "               'das18', 'das19', 'das20', 'das21', 'das22', 'das23', 'das24', 'das25',\n",
    "               'das26', 'das27', 'das28', 'das29', 'das30', 'das31', 'das32', 'das33',\n",
    "               'das34', 'das35']].astype(int)\n",
    "\n",
    "        targets = techniques       \n",
    "        techniques = targets.columns\n",
    "        #Transforms the scores in a high/low scale\"\n",
    "        for tech in techniques:\n",
    "            criteria = [targets[tech].between(0, 5), targets[tech].between(6, 10)]\n",
    "            values = [0, 1]\n",
    "            targets[tech] = np.select(criteria, values) \n",
    "            targets.astype(int)\n",
    "\n",
    "            techniques= pd.DataFrame(techniques) \n",
    "            targets= pd.DataFrame(targets) \n",
    "            \n",
    "        return  X, df, targets, techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3f508",
   "metadata": {},
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "176ee427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total participants in survey: 1995\n",
      "Total survey items: 78\n",
      "--------\n",
      "TIPI survey section- shape: (1995, 15)\n",
      "--------\n",
      "DAS survey section- shape: (1995, 42)\n",
      "--------\n",
      "Techniques survey section- shape: (1995, 30)\n"
     ]
    }
   ],
   "source": [
    "X, df, targets, techniques = data_to_ml()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65899cd8",
   "metadata": {},
   "source": [
    "## Persuasion techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea98dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Techniques_selected = targets[]\n",
    "\n",
    "# Test selected technique\n",
    "y =targets['t3_d2']\n",
    "\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee084ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e894e0d",
   "metadata": {},
   "source": [
    "## Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1603389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature shape: (1496, 48)\n",
      "------------\n",
      "Test feature shape: (499, 48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({1: 1109, 0: 387})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,shuffle=True) \n",
    "\n",
    "print (\"Train feature shape:\", X_train.shape)\n",
    "print('------------')\n",
    "print(\"Test feature shape:\", X_test.shape)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63eeaa",
   "metadata": {},
   "source": [
    "## Define sampling strategy i.e. balance binary classes using under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "385b507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y_train after balancing:-> Counter({0: 387, 1: 387})\n"
     ]
    }
   ],
   "source": [
    "# define sampling strategy\n",
    "under = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "counter\n",
    "print(f' y_train after balancing:-> {counter}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f17c0a",
   "metadata": {},
   "source": [
    "## Logistic Regresion Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5554f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaba77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9cd4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_scores( X_train, X_test, y_train, y_test):\n",
    "    '''Logist Regression function'''\n",
    "\n",
    "    \n",
    "    lg = LogisticRegression()\n",
    "    lg.fit(X_train, y_train)\n",
    "    \n",
    "    lg.score(X_test,y_test)\n",
    "    y_pred_untuned_lr = lg.predict(X_test)\n",
    "    #plot_confusion_matrix(lg, X_test, y_test, values_format = '.0f') \n",
    "    y_prob_untuned_lr = lg.predict_proba(X_test)[:, 1]\n",
    "    ba_untuned_lr = balanced_accuracy_score(y_test, y_pred_untuned_lr)\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.\n",
    "                format(ba_untuned_lr))\n",
    "    print(classification_report(y_test, y_pred_untuned_lr))\n",
    "    return lg, y_pred_untuned_lr, y_prob_untuned_lr, ba_untuned_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32c0f0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.62      0.44       134\n",
      "           1       0.80      0.57      0.67       365\n",
      "\n",
      "    accuracy                           0.58       499\n",
      "   macro avg       0.57      0.59      0.56       499\n",
      "weighted avg       0.68      0.58      0.61       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg, y_pred_untuned_lr, y_prob_untuned_lr, ba_untuned_lr = log_scores( X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9710bd3",
   "metadata": {},
   "source": [
    "## Pipeline for base without reducing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e2aa934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "# Create first pipeline for base without reducing features.\n",
    "\n",
    "pipe = Pipeline([('scaler' , StandardScaler()), ('classifier' , LogisticRegression())])\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = [{'classifier__penalty' : ['l1', 'l2'],\n",
    "               'classifier__C' : [100, 10, 1.0, 0.1, 0.01],\n",
    "               'classifier__solver' : ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "              ]\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(pipe, param_grid=param_grid, cv=10, verbose=True, n_jobs=-1, scoring='balanced_accuracy')\n",
    "\n",
    "# Fit on data\n",
    "best_clf_lr = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab263d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.62      0.45       134\n",
      "           1       0.81      0.58      0.67       365\n",
      "\n",
      "    accuracy                           0.59       499\n",
      "   macro avg       0.58      0.60      0.56       499\n",
      "weighted avg       0.68      0.59      0.61       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_tuned_lr = best_clf_lr.predict(X_test)\n",
    "y_prob_tuned_lr = best_clf_lr.predict_proba(X_test)[:, 1]\n",
    "ba_tuned_lr= balanced_accuracy_score(y_test, y_pred_tuned_lr)\n",
    "print(classification_report(y_test, y_pred_tuned_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f6fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ee23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ddb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2a36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
